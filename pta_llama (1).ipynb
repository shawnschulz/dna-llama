{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a4c38e-3899-4a17-9ae3-1caa2dcf92fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e47f949-73f3-4f8f-b12b-788ace727bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f76b2-974e-4fae-8ca3-3fa47e4810ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84811750-48d7-4bbe-a62e-349650d4f469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbcf4e2-8c22-444b-a4a4-9d0cfa3ac8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a49e5b-64ac-4000-9347-4cde66755b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install HTSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071c565-68a9-41f5-9dd0-f2eee269f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install enformer-pytorch>=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cd7ff-ef1f-46cc-99d5-386b71018d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2debb38-e289-4093-8237-544cad1b6395",
   "metadata": {},
   "source": [
    "## Load modules and variable declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9923688e-5f24-4f0f-8efa-34522c8d7480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/cgawad/conda_for_pf_notebook/miniconda3_for_pf/envs/pf/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import polars as pl\n",
    "from enformer_pytorch import Enformer, GenomeIntervalDataset\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc0bfa2-f9f6-44fc-9f55-c3e7ba22fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e148c112-2830-4546-a8ea-c283a3039703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can change the model path to any quantized model binary\n",
    "#TODO - make a script version of this with option for model path, relative context length, tsv_path, bam_path\n",
    "model_path=\"/scratch/users/sschulz/ggml-model-q4_1.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c32badd5-d1b6-428f-94a0-afa27e5234a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /scratch/users/sschulz/ggml-model-q4_1.bin\n",
      "llama_model_load_internal: format     = ggjt v1 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 6656\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 52\n",
      "llama_model_load_internal: n_layer    = 60\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 3 (mostly Q4_1)\n",
      "llama_model_load_internal: n_ff       = 17920\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 30B\n",
      "llama_model_load_internal: ggml ctx size = 110.30 KB\n",
      "llama_model_load_internal: mem required  = 25573.12 MB (+ 3124.00 MB per state)\n",
      "llama_init_from_file: kv self size  =  780.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9cc79-9b6f-46fe-94e0-5c3ffa1d4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_dir= \"/scratch/users/sschulz/pta_on_normal\"\n",
    "bed_path = \"/scratch/users/sschulz/pta_on_normal/chr10.bed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ce49a-d309-43e2-947c-cf5d6f4210de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#good testing but use a gvcf instead containing all known mutations first\n",
    "tsv_path = tsv_dir + \"/CARTPt04_Scan2_svc_merged_extract_snp.hg38_multianno.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85527b8e-22ef-447b-a239-a5c76b6ba3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv = pd.read_table(tsv_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08209602-e40c-4df6-a403-887fd5a14069",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv['CHROM'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac882d7-742f-46ee-af41-59474f5bc5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_path=tsv_dir + '/CART-MRD-BALL-PTA-NEXTERA-WGS-CCT5007Pt04-D4_S26.realigned_deduped_sorted.bam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88babbeb-1cae-431f-ae04-812d235fe189",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## get the gvcf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f66973-b4a6-4f18-997b-8607dbf0dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sav_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5346907-66fb-4495-8e04-75486e6393d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gvcf_dir = '/scratch/users/sschulz/pta_on_normal/gvcf'\n",
    "download_log_dir='scratch/users/sschulz/pta_on_normal/gvcf/logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd4f262-2392-49d6-86ae-26d64e07e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(gvcf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062284c-eb35-40a5-af7e-6e4ed1bf2072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_list = [chrom for sublist in [('MT', 'X', 'Y'), list(range(1,23))] for chrom in sublist]\n",
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ac3a2-c895-4781-bd0b-0e41b531ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadEnsembleGVCFs(output_dir, download_log_dir):\n",
    "    sav_dir = os.getcwd()\n",
    "    os.chdir(output_dir)\n",
    "    for i in [chrom for sublist in [('MT', 'X', 'Y'), list(range(1,23))] for chrom in sublist]:\n",
    "        command_ending = str(chrom) + '.gvf.gz'\n",
    "        print(f\"sbatch -c 2 --mem=32G -p cgawad --out={download_log_dir} --wrap='wget https://ftp.ensembl.org/pub/release-109/variation/gvf/homo_sapiens/homo_sapiens_incl_consequences-chr{i}.gvf.gz'\")\n",
    "        !sbatch -c 2 --mem=32G -p cgawad --out=$download_log_dir --wrap=f\"wget https://ftp.ensembl.org/pub/release-109/variation/gvf/homo_sapiens/homo_sapiens_incl_consequences-chr{i}.gvf.gz\"\n",
    "    os.chdir(sav_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917befbb-5687-429b-8c7a-b4c185d9f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadEnsembleGVCFs(gvcf_dir, download_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60072298-841f-4353-abd3-b14347740268",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ('MT', 'X', 'Y'):\n",
    "    print(f\"sbatch -c 2 --mem=32G -p cgawad --out='/scratch/users/sschulz/pta_on_normal/gvcf/logs/' --wrap='wget https://ftp.ensembl.org/pub/release-109/variation/gvf/homo_sapiens/homo_sapiens_incl_consequences-chr{i}.gvf.gz'\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7171e36-c62a-4c1d-8ff4-1ffa001dbe04",
   "metadata": {},
   "source": [
    "## Function and class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aefe47-2062-4751-83fd-d20c1176463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLlamaDataset(tsv_dir, bam_path, bed_path):\n",
    "    '''\n",
    "        from a directory containing many annotated tsv files and a bed path, create a huggingface dataset for use in llama\n",
    "        \n",
    "        start by just passing lines from vcf to llama for fine tuning, along with a line that says \n",
    "        \"The read/basepairs/sequence at this position is:\n",
    "        The read information from reference is:\"\n",
    "        \n",
    "        This is a pretty brute force way to do it but maybe it'll create something coherent from llama.\n",
    "        \n",
    "        \n",
    "        Getting correct sequence instruction: \n",
    "        \"instruction\": f\"The gene {gene} is mutated at the {start_pos} basepair. What is the sequence? What is the mutation?\",\n",
    "        \"input\": f\"{read_seq}\",\n",
    "        \"output\": \"5\"\n",
    "        \n",
    "        Getting whether exonic or not/amino acid change:\n",
    "        \n",
    "        \n",
    "        [WIP] Instrucitons incorporating answers from databases:\n",
    "        \n",
    "        Clinvar:\n",
    "        \n",
    "        NCBI:\n",
    "        \n",
    "        Genecards: \n",
    "        \n",
    "    '''\n",
    "    mutation_dictionary = {}\n",
    "    for filename in os.listdir(tsv_dir):\n",
    "        if filename.endswith('tsv'):\n",
    "            tsv_file = os.path.join(tsv_dir, filename)\n",
    "            tsv_length=len(tsv_file)\n",
    "            counter = 0\n",
    "            print(\"the tsv file is: \")\n",
    "            print(tsv_file)\n",
    "            for i in range(tsv_length):\n",
    "                chrom = tsv['CHROM'][i]\n",
    "                start_pos = tsv['POS'][i]\n",
    "                sample = tsv['SAMPLE'][i]\n",
    "                gene = tsv['Gene.refGene'][i]\n",
    "                gt = tsv['GT'][i]\n",
    "                alt = tsv['ALT'][i]\n",
    "     #           print(\"tsv from the tsv file is: \")\n",
    "      #          print(' '.join(tsv.columns))\n",
    "                if gt == '0/1' or gt == '1/1':\n",
    "                    print(start_pos)\n",
    "                    print(sample, gt)\n",
    "                    print(alt)\n",
    "                    print(gene)\n",
    "                    \n",
    "                    ### position of mutation is the position is says on the pileup - start position (0 indexed)\n",
    "                    ## start position can be greater than or less than position of read start, but luckily\n",
    "                    ## should be able to index the base that's changed either way \n",
    "                    \n",
    "                    #\n",
    "                    \n",
    "                    samfile = pysam.AlignmentFile(bam_path, \"rb\" )\n",
    "                    pileup = samfile.pileup(chrom, start_pos, start_pos+1, min_mapping_quality=58)\n",
    "                    for read in pileup:\n",
    "                        read_list = str(read).split('\\t')\n",
    "                        read_start = read_list[5]\n",
    "                        read_seq = read_list[11]\n",
    "                        \n",
    "                        mutated_base= read_seq[int(read_start) - start_pos] \n",
    "                        \n",
    "                \n",
    "                        print(f\"the start pos from tsv is {start_pos} the start pos from pileup is {read_start} the the gene is: \"+ gene +  ' the read is: ' + str(read_list) + ' and the mutated base is: ' + mutated_base)\n",
    "                        print('for sanity, the mutated allele was: ' + alt)\n",
    "                        mutation_dictionary[\"Reference Genome: hg38, Read: \" + read_seq] =  f\"the start pos from tsv is {start_pos} the start pos from pileup is {read_start} the the gene is: \"+ gene + ' and the mutated base is: ' + mutated_base\n",
    "                # for x in pileup:\n",
    "                #     if counter == 0:\n",
    "                #         print(str(x))\n",
    "\n",
    "    return(mutation_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e62c6-df07-43b4-a47e-e3fd4e5e906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "read = 'GTGTCAGACACTGTGGTGGAGCCCTACAACGCCACCCTCTCAGTCCACCAGCTCATAGAAAATGTGGATGAGACCTTCTGCATAGATAACGAAGCGCTAT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03972b0-2f80-4104-9542-bc9f14746e59",
   "metadata": {},
   "source": [
    "## Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d690a-c687-4ece-9e9b-d78345705c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Idea was to finetune with the dataset form makeLlamaDataset, but for now we are just trying to use it to do few shot learning by taking some examples\n",
    "    from it and using it to get it to tell you the mutated base in a read you give it\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87c57b-d478-41fb-bafa-cd2471663b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_dictionary = makeLlamaDataset(tsv_dir, bam_path, bed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfe0c2-8601-4f5d-8743-73a845235b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850671e8-f70e-45d3-acbe-431d8509d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can change the relative context length if you want to try and give the model more context, but 4 is already a lot and very slow\n",
    "relative_context_length = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb039e-a9ec-4efb-924d-3928fea4fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "prompt_string = ''\n",
    "for key in prompt_dictionary.keys():\n",
    "    counter += 1\n",
    "    if counter < relative_context_length:\n",
    "        prompt_string += \"Input: \" + key + \"\\n\" + \" Output: \" + prompt_dictionary[key] + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23474ee-3757-4bb7-b094-c050dfa8d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54018a93-9beb-4ab3-8edd-73a2337b69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to check if llama is working\n",
    "prompt = \"Why do giraffes have long necks?\"\n",
    "output = llm(\"\\n\" + \"Input: \" + prompt + \"\\n\" + \"Output: \", max_tokens=32, stop=[\"Input:\"], echo=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec31d8-35d7-4906-84b5-943bdc5225f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Reference Genome: hg38, Read: TAGAAAATGTGGATGAGACCTTCTGCATAGATAACGAAGCGCTATATGACATATGTTCCAGGACCCTAAAACTGCCCACACCCACCTATGGTGACCTGAA'\n",
    "output = llm(prompt_string + \"\\n\" + \"Input: \" + prompt + \"\\n\" + \"Output: \", max_tokens=32, stop=[\"Input:\"], echo=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081b19a-a1a4-40e2-b0da-d087d4f4cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_dictionary[prompt])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
