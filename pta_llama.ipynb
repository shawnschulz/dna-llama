{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a4c38e-3899-4a17-9ae3-1caa2dcf92fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e47f949-73f3-4f8f-b12b-788ace727bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f76b2-974e-4fae-8ca3-3fa47e4810ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84811750-48d7-4bbe-a62e-349650d4f469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbcf4e2-8c22-444b-a4a4-9d0cfa3ac8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a49e5b-64ac-4000-9347-4cde66755b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install HTSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071c565-68a9-41f5-9dd0-f2eee269f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install enformer-pytorch>=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cd7ff-ef1f-46cc-99d5-386b71018d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2debb38-e289-4093-8237-544cad1b6395",
   "metadata": {},
   "source": [
    "## Load modules and variable declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8585ddc7-8e8a-4674-9609-0d31e7c7e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnaDataSet import dnaDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9923688e-5f24-4f0f-8efa-34522c8d7480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import polars as pl\n",
    "from enformer_pytorch import Enformer, GenomeIntervalDataset\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import json \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0bfa2-f9f6-44fc-9f55-c3e7ba22fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e148c112-2830-4546-a8ea-c283a3039703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can change the model path to any quantized model binary\n",
    "#TODO - make a script version of this with option for model path, relative context length, tsv_path, bam_path\n",
    "modelPath=\"/scratch/users/sschulz/ggml-model-q4_1.bin\"\n",
    "memoryDir=\"/scratch/users/sschulz/llm_memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32badd5-d1b6-428f-94a0-afa27e5234a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llama(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9cc79-9b6f-46fe-94e0-5c3ffa1d4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_dir= \"/scratch/users/sschulz/pta_on_normal\"\n",
    "bed_path = \"/scratch/users/sschulz/pta_on_normal/chr10.bed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ce49a-d309-43e2-947c-cf5d6f4210de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#good testing but use a gvcf instead containing all known mutations first\n",
    "tsv_path = tsv_dir + \"/CARTPt04_Scan2_svc_merged_extract_snp.hg38_multianno.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85527b8e-22ef-447b-a239-a5c76b6ba3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv = pd.read_table(tsv_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08209602-e40c-4df6-a403-887fd5a14069",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv['CHROM'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac882d7-742f-46ee-af41-59474f5bc5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_path=tsv_dir + '/CART-MRD-BALL-PTA-NEXTERA-WGS-CCT5007Pt04-D4_S26.realigned_deduped_sorted.bam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88babbeb-1cae-431f-ae04-812d235fe189",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## get the gvcf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f66973-b4a6-4f18-997b-8607dbf0dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sav_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5346907-66fb-4495-8e04-75486e6393d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gvcf_dir = '/scratch/users/sschulz/pta_on_normal/gvcf'\n",
    "download_log_dir='scratch/users/sschulz/pta_on_normal/gvcf/logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd4f262-2392-49d6-86ae-26d64e07e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(gvcf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062284c-eb35-40a5-af7e-6e4ed1bf2072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_list = [chrom for sublist in [('MT', 'X', 'Y'), list(range(1,23))] for chrom in sublist]\n",
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ac3a2-c895-4781-bd0b-0e41b531ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadEnsembleGVCFs(output_dir, download_log_dir):\n",
    "    sav_dir = os.getcwd()\n",
    "    os.chdir(output_dir)\n",
    "    for i in [chrom for sublist in [('MT', 'X', 'Y'), list(range(1,23))] for chrom in sublist]:\n",
    "        command_ending = str(chrom) + '.gvf.gz'\n",
    "        print(f\"sbatch -c 2 --mem=32G -p cgawad --out={download_log_dir} --wrap='wget https://ftp.ensembl.org/pub/release-109/variation/gvf/homo_sapiens/homo_sapiens_incl_consequences-chr{i}.gvf.gz'\")\n",
    "        !sbatch -c 2 --mem=32G -p cgawad --out=$download_log_dir --wrap=f\"wget https://ftp.ensembl.org/pub/release-109/variation/gvf/homo_sapiens/homo_sapiens_incl_consequences-chr{i}.gvf.gz\"\n",
    "    os.chdir(sav_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917befbb-5687-429b-8c7a-b4c185d9f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadEnsembleGVCFs(gvcf_dir, download_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60072298-841f-4353-abd3-b14347740268",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ('MT', 'X', 'Y'):\n",
    "    print(f\"sbatch -c 2 --mem=32G -p cgawad --out='/scratch/users/sschulz/pta_on_normal/gvcf/logs/' --wrap='wget https://ftp.ensembl.org/pub/release-109/variation/gvf/homo_sapiens/homo_sapiens_incl_consequences-chr{i}.gvf.gz'\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7171e36-c62a-4c1d-8ff4-1ffa001dbe04",
   "metadata": {},
   "source": [
    "## Function and class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f42f06b-ab0b-4ab1-8841-e43a99084677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is all in the dnaDataSet python file but I've kept it here just in case lol\n",
    " class dnaDataSet:\n",
    "    def save(self, fp):\n",
    "        '''\n",
    "            save dnaDataSet as pickle somewhere\n",
    "        '''\n",
    "        file_name = fp\n",
    "        with open(file_name, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "            print(f'dnaDataSet object successfully saved to \"{file_name}\"')\n",
    "    \n",
    "    def __init__(self, modelPath=False, memoryDir=os.getcwd()):\n",
    "        self.mutationDictionary={}\n",
    "        self.bamsDictionary={}\n",
    "        self.tsv=pd.DataFrame()\n",
    "        self.relativeContextLength=4\n",
    "        self.memoryDir=memoryDir\n",
    "        #promptOutput is a string formatted as a hf dataset\n",
    "        self.promptOutput=''\n",
    "        self.modelPath=modelPath\n",
    "    \n",
    "    def __getitem__(self, position):\n",
    "        '''\n",
    "        '''\n",
    "        items=[\n",
    "            self.mutationDictionary,\n",
    "            self.bamsDictionary,\n",
    "            self.tsv,\n",
    "            self.relativeContextLength,\n",
    "            self.memoryDir,\n",
    "            #promptOutput is a string formatted as a hf dataset\n",
    "            self.promptOutput\n",
    "        ]\n",
    "        return items[position]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        '''\n",
    "            \n",
    "        '''\n",
    "        return f'dnaDataSet object\\n current model being used: {str(self.modelPath)},\\n mutationDictionary: {str(self.mutationDictionary)},\\n bamsDictionary: {str(self.bamsDictionary)},\\n tsv: {str(self.tsv)},\\n relativeContextLength: {str(self.relativeContextLength)},\\n memoryDir: {str(self.memoryDir)},\\n promptOutput: {str(self.promptOutput)}'\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        '''\n",
    "            returns a dnaDataset with consolidated mutationDictionary and bamsDictionary, however other info is kept from the first dictionary\n",
    "        '''\n",
    "        selfCopy = self\n",
    "        otherCopy = other\n",
    "        selfCopy.mutationDictionary.update(otherCopy.mutationDictionary)\n",
    "        selfCopy.bamDictionary.update(otherCopy.mutationDictionary)\n",
    "        return selfCopy\n",
    "    \n",
    "    def __len__(self):\n",
    "        '''\n",
    "            prints the length of the mutationDictioanry keys\n",
    "        '''\n",
    "        print(\"The length of the mutationDictionary keys is :\")\n",
    "        return(len(self.mutationDictionary))\n",
    "    \n",
    "    def setRelativeContextLength(self, contextLength):\n",
    "        '''\n",
    "            takes int contextLength and sets it in the dataset\n",
    "        '''\n",
    "        self.relativeContextLength=contextLength\n",
    "    \n",
    "    def saveOutput(self, fp, memoryDir=False):\n",
    "        '''\n",
    "            saves the output of a prompting to memoryDir by default (so it can be used automtically when calling prompting), but can also be called\n",
    "            to save where user specifies filepath\n",
    "        '''\n",
    "        if not memoryDir:\n",
    "            self.promptOutput.save_to_disk(fp)\n",
    "        else:\n",
    "            self.promptOutput.save_to_disk(self.memoryDir + '/' + fp)\n",
    "    \n",
    "    def saveMutationDictionary(self, fp, memoryDir=False):\n",
    "        '''\n",
    "            saves mutationDictionary produced from tsv file and bam files to memoryDir by default as json file, but can also be called to save where user\n",
    "            specifies filepath\n",
    "        '''\n",
    "        if not memoryDir:\n",
    "            with open(fp, \"w\") as outfile:\n",
    "                json.dump(self.mutationDictionary, outfile)\n",
    "        else:\n",
    "            with open(self.memoryDir + '/' + fp, \"w\") as outfile:\n",
    "                json.dump(self.mutationDictionary, outfile)\n",
    "    \n",
    "    def makeLlamaDataset(self, tsv_dir, bam_path, bed_path):\n",
    "        '''\n",
    "            from a directory containing an annotated tsv file, many bam files and a bed path, create a huggingface dataset for use in llama\n",
    "\n",
    "            start by just passing lines from vcf to llama for fine tuning, along with a line that says \n",
    "            \"The read/basepairs/sequence at this position is:\n",
    "            The read information from reference is:\"\n",
    "\n",
    "            This is a pretty brute force way to do it but maybe it'll create something coherent from llama.\n",
    "\n",
    "\n",
    "            Getting correct sequence instruction: \n",
    "            \"instruction\": f\"The gene {gene} is mutated at the {start_pos} basepair. What is the sequence? What is the mutation?\",\n",
    "            \"input\": f\"{read_seq}\",\n",
    "            \"output\": \"5\"\n",
    "\n",
    "            Getting whether exonic or not/amino acid change:\n",
    "\n",
    "\n",
    "            [WIP] Instrucitons incorporating answers from databases:\n",
    "\n",
    "            Clinvar:\n",
    "\n",
    "            NCBI:\n",
    "\n",
    "            Genecards: \n",
    "\n",
    "        '''\n",
    "        for filename in os.listdir(tsv_dir):\n",
    "            if filename.endswith('tsv'):\n",
    "                tsv_file = os.path.join(tsv_dir, filename)\n",
    "                tsv_length=len(tsv_file)\n",
    "                counter = 0\n",
    "                print(\"the tsv file is: \")\n",
    "                print(tsv_file)\n",
    "                for i in range(tsv_length):\n",
    "                    chrom = tsv['CHROM'][i]\n",
    "                    start_pos = tsv['POS'][i]\n",
    "                    sample = tsv['SAMPLE'][i]\n",
    "                    gene = tsv['Gene.refGene'][i]\n",
    "                    gt = tsv['GT'][i]\n",
    "                    alt = tsv['ALT'][i]\n",
    "         #           print(\"tsv from the tsv file is: \")\n",
    "          #          print(' '.join(tsv.columns))\n",
    "                    if gt == '0/1' or gt == '1/1':\n",
    "                        print(start_pos)\n",
    "                        print(sample, gt)\n",
    "                        print(alt)\n",
    "                        print(gene)\n",
    "\n",
    "                        ### position of mutation is the position is says on the pileup - start position (0 indexed)\n",
    "                        ## start position can be greater than or less than position of read start, but luckily\n",
    "                        ## should be able to index the base that's changed either way \n",
    "\n",
    "                        #\n",
    "\n",
    "                        samfile = pysam.AlignmentFile(bam_path, \"rb\" )\n",
    "                        self.bamsDictionary[bam_path] = samfile\n",
    "                        pileup = samfile.pileup(chrom, start_pos, start_pos+1, min_mapping_quality=58)\n",
    "                        for read in pileup:\n",
    "                            read_list = str(read).split('\\t')\n",
    "                            read_start = read_list[5]\n",
    "                            read_seq = read_list[11]\n",
    "\n",
    "                            mutated_base= read_seq[int(read_start) - start_pos] \n",
    "\n",
    "\n",
    "                            print(f\"the start pos from tsv is {start_pos} the start pos from pileup is {read_start} the the gene is: \"+ gene +  ' the read is: ' + str(read_list) + ' and the mutated base is: ' + mutated_base)\n",
    "                            print('for sanity, the mutated allele was: ' + alt)\n",
    "                            self.mutationDictionary[\"Reference Genome: hg38, Read: \" + read_seq] =  f\"the start pos from tsv is {start_pos} the start pos from pileup is {read_start} the the gene is: \"+ gene + ' and the mutated base is: ' + mutated_base\n",
    "                    # for x in pileup:\n",
    "                    #     if counter == 0:\n",
    "                    #         print(str(x))\n",
    "\n",
    "        return(mutation_dictionary)\n",
    "    def fewShotLearning(self, read):\n",
    "        '''\n",
    "            takes a read as a prompt\n",
    "        '''\n",
    "        counter = 0\n",
    "        prompt_string = ''\n",
    "        for key in self.mutationDictionary.keys():\n",
    "            counter += 1\n",
    "            if counter < self.relativeContextLength:\n",
    "                prompt_string += \"Input: \" + key + \"\\n\" + \" Output: \" + self.mutationDictionary[key] + \"\\n\"\n",
    "        prompt = 'Reference Genome: hg38, Read: ' + read\n",
    "        output = llm(prompt_string + \"\\n\" + \"Input: \" + prompt + \"\\n\" + \"Output: \", max_tokens=32, stop=[\"Input:\"], echo=True)\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ca9be-1930-48e4-8932-c1aea12ea0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLlama(dnaset, prompt):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aefe47-2062-4751-83fd-d20c1176463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLlamaDataset(tsv_dir, bam_path, bed_path):\n",
    "    '''\n",
    "        from a directory containing many annotated tsv files and a bed path, create a huggingface dataset for use in llama\n",
    "        \n",
    "        start by just passing lines from vcf to llama for fine tuning, along with a line that says \n",
    "        \"The read/basepairs/sequence at this position is:\n",
    "        The read information from reference is:\"\n",
    "        \n",
    "        This is a pretty brute force way to do it but maybe it'll create something coherent from llama.\n",
    "        \n",
    "        \n",
    "        Getting correct sequence instruction: \n",
    "        \"instruction\": f\"The gene {gene} is mutated at the {start_pos} basepair. What is the sequence? What is the mutation?\",\n",
    "        \"input\": f\"{read_seq}\",\n",
    "        \"output\": \"5\"\n",
    "        \n",
    "        Getting whether exonic or not/amino acid change:\n",
    "        \n",
    "        \n",
    "        [WIP] Instrucitons incorporating answers from databases:\n",
    "        \n",
    "        Clinvar:\n",
    "        \n",
    "        NCBI:\n",
    "        \n",
    "        Genecards: \n",
    "        \n",
    "    '''\n",
    "    mutation_dictionary = {}\n",
    "    for filename in os.listdir(tsv_dir):\n",
    "        if filename.endswith('tsv'):\n",
    "            tsv_file = os.path.join(tsv_dir, filename)\n",
    "            tsv_length=len(tsv_file)\n",
    "            counter = 0\n",
    "            print(\"the tsv file is: \")\n",
    "            print(tsv_file)\n",
    "            for i in range(tsv_length):\n",
    "                chrom = tsv['CHROM'][i]\n",
    "                start_pos = tsv['POS'][i]\n",
    "                sample = tsv['SAMPLE'][i]\n",
    "                gene = tsv['Gene.refGene'][i]\n",
    "                gt = tsv['GT'][i]\n",
    "                alt = tsv['ALT'][i]\n",
    "     #           print(\"tsv from the tsv file is: \")\n",
    "      #          print(' '.join(tsv.columns))\n",
    "                if gt == '0/1' or gt == '1/1':\n",
    "                    print(start_pos)\n",
    "                    print(sample, gt)\n",
    "                    print(alt)\n",
    "                    print(gene)\n",
    "                    \n",
    "                    ### position of mutation is the position is says on the pileup - start position (0 indexed)\n",
    "                    ## start position can be greater than or less than position of read start, but luckily\n",
    "                    ## should be able to index the base that's changed either way \n",
    "                    \n",
    "                    #\n",
    "                    \n",
    "                    samfile = pysam.AlignmentFile(bam_path, \"rb\" )\n",
    "                    pileup = samfile.pileup(chrom, start_pos, start_pos+1, min_mapping_quality=58)\n",
    "                    for read in pileup:\n",
    "                        read_list = str(read).split('\\t')\n",
    "                        read_start = read_list[5]\n",
    "                        read_seq = read_list[11]\n",
    "                        \n",
    "                        mutated_base= read_seq[int(read_start) - start_pos] \n",
    "                        \n",
    "                \n",
    "                        print(f\"the start pos from tsv is {start_pos} the start pos from pileup is {read_start} the the gene is: \"+ gene +  ' the read is: ' + str(read_list) + ' and the mutated base is: ' + mutated_base)\n",
    "                        print('for sanity, the mutated allele was: ' + alt)\n",
    "                        mutation_dictionary[\"Reference Genome: hg38, Read: \" + read_seq] =  f\"the start pos from tsv is {start_pos} the start pos from pileup is {read_start} the the gene is: \"+ gene + ' and the mutated base is: ' + mutated_base\n",
    "                # for x in pileup:\n",
    "                #     if counter == 0:\n",
    "                #         print(str(x))\n",
    "\n",
    "    return(mutation_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e62c6-df07-43b4-a47e-e3fd4e5e906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "read = 'GTGTCAGACACTGTGGTGGAGCCCTACAACGCCACCCTCTCAGTCCACCAGCTCATAGAAAATGTGGATGAGACCTTCTGCATAGATAACGAAGCGCTAT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d053bf-dc37-4730-9fa9-327eb3738752",
   "metadata": {},
   "source": [
    "## test stuff with the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec835f2-9b1e-4d54-8bb8-1c842375ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnaset = dnaDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01afb7f0-fb80-44b5-921f-1353839132dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dnaDataSet object\n",
       " current model being used: False,\n",
       " mutationDictionary: {},\n",
       " bamsDictionary: {},\n",
       " tsv: Empty DataFrame\n",
       "Columns: []\n",
       "Index: [],\n",
       " relativeContextLength: 4,\n",
       " memoryDir: /oak/stanford/groups/cgawad/Scripts/dna-llama,\n",
       " promptOutput: "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnaset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "770d0dfc-f77b-490d-8ff9-656b8f28c566",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelPath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dnaset2\u001b[38;5;241m=\u001b[39mdnaDataSet(modelPath\u001b[38;5;241m=\u001b[39m\u001b[43mmodelPath\u001b[49m, memoryDir\u001b[38;5;241m=\u001b[39mmemoryDir)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelPath' is not defined"
     ]
    }
   ],
   "source": [
    "dnaset2=dnaDataSet(modelPath=modelPath, memoryDir=memoryDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0a7d5-3c10-4f49-8b6b-1d9c9182ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnaset2.save(\"/scratch/users/sschulz/dnaset.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03972b0-2f80-4104-9542-bc9f14746e59",
   "metadata": {},
   "source": [
    "## Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d690a-c687-4ece-9e9b-d78345705c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Idea was to finetune with the dataset form makeLlamaDataset, but for now we are just trying to use it to do few shot learning by taking some examples\n",
    "    from it and using it to get it to tell you the mutated base in a read you give it\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77160857-93c0-4a99-851e-a846c592c0a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dnaset2.makeLlamaDataset(tsv_dir, bam_path, bed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df6dea-f5d2-4ad3-83dc-4c96bed2145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnaset2.fewShotLearning('TAGAAAATGTGGATGAGACCTTCTGCATAGATAACGAAGCGCTATATGACATATGTTCCAGGACCCTAAAACTGCCCACACCCACCTATGGTGACCTGAA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
