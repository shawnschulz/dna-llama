{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8de9751-8866-4526-b274-44feef488af1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af887b-d7f5-4512-b520-a2bcec7c52d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d675a-8a92-4c71-b914-3270fa0e3b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41bc32-41dd-4ca3-b022-a65ca8c64780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046270b1-fc50-4cbd-8d0a-42e911db6842",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b73f1-d345-4826-af49-5c33c2705cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install HTSeq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd47b9f-8428-41aa-a1c3-caecc2b4f3dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading DNA sequence data from BAMs to create dataset for fine tuning DNABERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d4db1-4610-4c72-8828-0f68465ce04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import HTSeq\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ecb28c-3067-4417-94d8-94910c2f9011",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def addBAM(bam_path, vcf_path):\n",
    "    '''\n",
    "        Given a path pointing ot a bam file, return a json or hf dataset object with following info:\n",
    "            1. iterate through the bam file and get sequence info on reads containing mutations appearing in vcf file\n",
    "            2. for each read want to have the chr #, description, and whther it is in exonic portion of a gene\n",
    "                -if not exonic, ideally want what type non-coding element the read is a part of\n",
    "            3. If a mutation, want info for Mutation from Clinvar, Cosmic, NCBI\n",
    "            4. desc of gene from NCBI \n",
    "            \n",
    "            desc of sam_alignment from htseq:\n",
    "                >>> aln.iv\n",
    "                <GenomicInterval object 'IV', [246048,246084), strand '+'>\n",
    "                >>> aln.iv.chrom\n",
    "                'IV'\n",
    "                >>> aln.iv.start\n",
    "                246048\n",
    "                >>> aln.iv.end\n",
    "                246084\n",
    "                >>> aln.iv.strand\n",
    "                '+'\n",
    "    '''\n",
    "    data_dict = {}\n",
    "    with HTSeq.BAM_Reader(bam_path) as f:\n",
    "        for i, sam_alignment in enumerate(f):\n",
    "            ### did this a alittle backwards, should iterate through gtf file to get gene name and interval, then (hopefully) use that\n",
    "            ### to index into the bam file to get the sequence rather than iterating through all parts of the bam file\n",
    "            if sam_alignment.aligned == True:\n",
    "                ### i'm not sure what's gonna be the most useful thing for llama to map all the info to, starting with a string with\n",
    "                ### chrom and pos and what file it's from\n",
    "                chrom_pos_identifier = sam_alignment.iv.chrom + ' START: ' + sam_alignment.iv.start + ' END: ' + sam_alignment.iv.end \n",
    "                data_dict[chrom_pos_identifier] = [\n",
    "                {\n",
    "                    'read_name':sam_alignment.read.name\n",
    "                    'seq':sam_alignment.read,\n",
    "                }\n",
    "                ]\n",
    "            print(read)\n",
    "            ## for testing don't do the whole thing\n",
    "            if i == 2:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7da0d2-d581-4e52-a926-b7e5440f2ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareBertDataset(bam_file, vcf_file):\n",
    "    '''\n",
    "        get mutations from vcf file, then get the read containing that mutation from the bam file, then mask that mutation and format\n",
    "        for BERT (i.e. token with the mask at the mutation position so it can learn with PTA artifacts look like\n",
    "        \n",
    "        dataset should look like this:\n",
    "        DatasetDict({\n",
    "                train: Dataset({\n",
    "                    features: ['squence', 'label'],\n",
    "                    num_rows: 25000\n",
    "                })\n",
    "                test: Dataset({\n",
    "                    features: ['sequence', 'label'],\n",
    "                    num_rows: 25000\n",
    "                })\n",
    "                unsupervised: Dataset({\n",
    "                    features: ['sequence', 'label'],\n",
    "                    num_rows: 50000\n",
    "                })\n",
    "            })\n",
    "        \n",
    "        for row in sample:\n",
    "            print(f\"\\n'>>> Sequence: {row['sequence']}'\")\n",
    "            print(f\"'>>> Label: {row['label']}'\")\n",
    "\n",
    "        '>>> Sequence: ACTAGATAGATA'\n",
    "        '>>> Label: 0'\n",
    "                            \n",
    "        '>>> Review: ACATAGATATATA'\n",
    "                                ^\n",
    "                            mutated base\n",
    "        '>>> Label: 1'\n",
    "        \n",
    "        ### If we do this the model will only learn whether a mutation is in the sequence, can we label it so the number corresponds to\n",
    "        ### what base is mutated, i.e. 0 is no mutation?\n",
    "        \n",
    "        '>>> Sequence: ACTAGATAGATA'\n",
    "        '>>> Label: 0'\n",
    "                            \n",
    "        '>>> Review: ACATAGATATATA'\n",
    "                                ^\n",
    "                            mutated base\n",
    "        '>>> Label: 12'\n",
    "        \n",
    "        ### this also seems like it won't leverage the power of the whole dna sequence\n",
    "        \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80716db5-0ae6-4fa1-8d5c-f5760607acf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb4666ae-b35a-4db7-a06f-bc509483d28f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DNA tokenizer Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a75ed6-81f5-4cce-9b67-f2178767f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AIRI-Institute/gena-lm-bert-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2f48d-03fd-4271-8e32-2a155a5d450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(\"ACGTGGTATGATGATAGATGATGA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee442c-4a03-4a89-a14f-ca606ba062fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a08383-f1c8-4609-8b52-ee14a105f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ab69da-04ca-4442-89a0-2d00f322fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sequences = [\n",
    "    \"ACGTAGCTGACTGACTTAGTGA\",\n",
    "    \"ACTAGCATGCATCGTAGCTAGCTAGACTGA\",\n",
    "    \"ATATATATTACACACACGAGACTAGCTT\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1c782-cd9f-4150-a6b4-596d00c0b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input=tokenizer(batch_sequences, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5b846-3692-4424-b49f-bccd5fb95e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701126e-e8d3-4fca-8e33-8aa6dc2bab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in encoded_input['input_ids']:\n",
    "    print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce5d5e-6108-43ba-947e-8f75d9ee9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## p much above but we've padded, truncated (no maximum length provided tho) and returned tensors\n",
    "encoded_input = tokenizer(batch_sequences, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f52667f-29e9-4316-8659-110545deae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## so we can tokenize DNA sequences, but how do we "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
